import streamlit as st
# ğŸ”‘ set_page_config å¿…é¡»æœ€å…ˆä¸”åªè°ƒç”¨ä¸€æ¬¡
st.set_page_config(page_title="AirGuard â€“ Airbnb Listing Classifier", page_icon="ğŸ ", layout="wide")

# ================== è½»é‡æ ·å¼ï¼ˆå¡ç‰‡/å‘å…‰/é¡¶éƒ¨æ /å­—ä½“ï¼‰ ==================
st.markdown("""
<style>
:root { --glass: rgba(255,255,255,0.06); --glass2: rgba(255,255,255,0.03); }
.block-container { padding-top: 0.6rem; }
.topbar {position: sticky; top: 0; z-index: 100; backdrop-filter: blur(8px);
  background: rgba(11,12,16,0.65); border-bottom: 1px solid rgba(255,255,255,0.06); padding: 10px 8px;}
.topbar .brand {font-weight:700; letter-spacing:.5px;}
.kcard {border: 1px solid var(--glass); background: linear-gradient(180deg, var(--glass2), rgba(255,255,255,0.02));
  border-radius: 16px; padding: 16px; }
.glow {box-shadow: 0 0 0px rgba(124,92,255,0.0);}
.glow:hover {box-shadow: 0 0 22px rgba(124,92,255,0.25); transition: box-shadow .25s ease;}
.section-title {font-size: 20px; font-weight: 700; margin: 6px 0 10px;}
.small {opacity:.8; font-size: 13px;}
.footer {opacity:.65; font-size:12px; padding:24px 0 8px 0; text-align:center;}
.badge {display:inline-block; padding:4px 10px; border-radius:999px; font-weight:700; font-size:13px;}
.badge-green {background:#17351f; color:#8ef0a6; border:1px solid #214f30;}
.badge-yellow {background:#3c3310; color:#ffe27a; border:1px solid #5a4a16;}
.badge-red {background:#3a1518; color:#ff9aa2; border:1px solid #5a1f24;}
</style>
<div class="topbar">
  <span class="brand">ğŸ  AirGuard</span>
  <span style="opacity:.6; margin-left:8px;">Anomaly & Risk Insight</span>
</div>
<div style="padding: 10px 0 6px 0;">
  <div style="font-size:28px; font-weight:800;">åŸå¸‚çº§æˆ¿æºå¼‚å¸¸æ£€æµ‹</div>
  <div class="small">æŒ‰åŸå¸‚åŠ è½½èšç±»åŸºçº¿ Â· å£è¯­åŒ–è§£é‡Š Â· ä¸€é”®è¯„ä¼°</div>
</div>
""", unsafe_allow_html=True)

# ================== Imports ==================
import json
import joblib
import numpy as np
import pandas as pd
from collections import Counter
from sklearn.metrics.pairwise import euclidean_distances
from sklearn.metrics import classification_report, confusion_matrix
from pathlib import Path
import hashlib

# ================== åŸå¸‚é…ç½® ==================
CITY_OPTIONS = {
    "NYC": {"label": "çº½çº¦ NYC", "default_rare_threshold": 0.04},
    "SF":  {"label": "æ—§é‡‘å±± SF", "default_rare_threshold": 0.05},
    "LA":  {"label": "æ´›æ‰çŸ¶ LA", "default_rare_threshold": 0.05},
    "SEA": {"label": "è¥¿é›…å›¾ SEA", "default_rare_threshold": 0.05},
}

# ============== å·¥ä»¶åŠ è½½ ==============
@st.cache_resource
def load_artifacts(city: str):
    base = Path(__file__).parent / city
    try:
        scaler = joblib.load(base / "scaler.pkl")
        with open(base / "top_features.json","r") as f:
            top_features = json.load(f)
        X_scaled = np.load(base / "X_scaled.npy")
        cluster_labels = np.load(base / "cluster_labels.npy")
    except Exception as e:
        raise RuntimeError(f"[{city}] åŠ è½½å·¥ä»¶å¤±è´¥ï¼š{e}")
    return scaler, top_features, X_scaled, cluster_labels

# ============== åˆ¤å®šå‡½æ•°ï¼ˆä½ çš„åŸå‡½æ•°ï¼‰ ==============
def classify_listing_from_raw_input(user_input_raw, top_features, scaler, X_scaled, cluster_labels, rare_threshold=0.04):
    df_input = pd.DataFrame([user_input_raw])

    # å¼ºåˆ¶æ•°å€¼ç±»å‹/é»˜è®¤å€¼
    df_input["PRICE"] = df_input["PRICE"].astype(float)
    df_input["REVIEWS_PER_MONTH"] = df_input["REVIEWS_PER_MONTH"].astype(float)
    df_input["HOST_LISTINGS_COUNT"] = df_input["HOST_LISTINGS_COUNT"].astype(float)
    df_input["AVAILABILITY_365"] = df_input["AVAILABILITY_365"].astype(float)
    df_input["BEDROOMS"] = df_input["BEDROOMS"].fillna(1)
    df_input["BEDS"] = df_input["BEDS"].fillna(1)

    # è¡ç”Ÿç‰¹å¾
    df_input["LOG_PRICE"] = np.log1p(df_input["PRICE"])
    df_input["LOG_REVIEWS_PER_MONTH"] = np.log1p(df_input["REVIEWS_PER_MONTH"])
    df_input["LOG_HOST_LISTINGS_COUNT"] = np.log1p(df_input["HOST_LISTINGS_COUNT"])
    df_input["LOG_AVAILABILITY_365"] = np.log1p(df_input["AVAILABILITY_365"])
    df_input["LISTING_DENSITY"] = df_input["REVIEWS_PER_MONTH"] / (df_input["AVAILABILITY_365"] + 1)
    df_input["BEDROOM_BED_RATIO"] = df_input["BEDROOMS"] / (df_input["BEDS"] + 1)

    # One-hot
    room_dummies = pd.get_dummies(df_input.get("ROOM_TYPE", pd.Series(dtype=str)), prefix="ROOM_TYPE")
    prop_dummies = pd.get_dummies(df_input.get("PROPERTY_TYPE", pd.Series(dtype=str)), prefix="PROPERTY_TYPE")
    df_input = pd.concat([df_input, room_dummies, prop_dummies], axis=1)

    # å¯¹é½ç‰¹å¾
    for col in top_features:
        if col not in df_input.columns:
            df_input[col] = 0

    X_user = df_input[top_features]
    X_user_scaled = scaler.transform(X_user)

    # è·ç¦»ä¸ç°‡ä¸­å¿ƒ
    from numpy import ndarray
    cluster_sizes = Counter(cluster_labels)
    cluster_centers, cluster_distances = {}, {}

    unique_labels = set(cluster_labels.tolist() if isinstance(cluster_labels, ndarray) else cluster_labels)
    for label in unique_labels:
        if label == -1:
            continue
        mask = (cluster_labels == label)
        cluster_points = X_scaled[mask]
        center = cluster_points.mean(axis=0)
        cluster_centers[label] = center
        dist = euclidean_distances(X_user_scaled, center.reshape(1, -1))[0][0]
        cluster_distances[label] = float(dist)

    if not cluster_distances:
        return {"type": "anomaly", "reason": "No clusters available."}

    closest_cluster = min(cluster_distances, key=cluster_distances.get)
    closest_distance = cluster_distances[closest_cluster]
    cluster_ratio = cluster_sizes[closest_cluster] / len(cluster_labels)

    own_distances = euclidean_distances(
        X_scaled[cluster_labels == closest_cluster],
        cluster_centers[closest_cluster].reshape(1, -1)
    )
    abnormal_cutoff = float(np.percentile(own_distances, 95))

    # åœ¨è¿”å›ç»“æœå‰ï¼Œå…ˆç®— p_in_cluster
    p_in_cluster = percentile_rank(
        euclidean_distances(X_scaled[cluster_labels == closest_cluster],
                            cluster_centers[closest_cluster].reshape(1, -1)).reshape(-1),
        closest_distance
    )

    if closest_distance > abnormal_cutoff:
        label_type = "anomaly"
    elif p_in_cluster >= 80:   # ğŸ‘ˆ æ–°å¢é€»è¾‘
        label_type = "rare"
    elif cluster_ratio < rare_threshold:
        label_type = "rare"
    else:
        label_type = "typical"


    return {
        "type": label_type,
        "closest_cluster": int(closest_cluster),
        "cluster_size_ratio": round(float(cluster_ratio), 4),
        "distance_to_cluster_center": round(float(closest_distance), 4),
        "abnormal_cutoff": round(float(abnormal_cutoff), 4),
        "all_cluster_distances": dict(sorted(cluster_distances.items(), key=lambda kv: kv[1])),
        "percentile_in_cluster": round(float(p_in_cluster), 2)

    }

# ============== è¯„ä¼°å‡½æ•° ==============
def evaluate_anomaly_detector(test_listings, classify_func, top_features, scaler, X_scaled, cluster_labels):
    y_true, y_pred = [], []
    for listing in test_listings:
        listing = listing.copy()
        label = listing.pop("LABEL")
        y_true.append(label)
        try:
            result = classify_func(
                user_input_raw=listing,
                top_features=top_features,
                scaler=scaler,
                X_scaled=X_scaled,
                cluster_labels=cluster_labels
            )
            y_pred.append(result.get("type", "error"))
        except Exception:
            y_pred.append("error")

    labels_order = ["typical", "rare", "anomaly"]
    cm = confusion_matrix(y_true, y_pred, labels=labels_order)
    report = classification_report(y_true, y_pred, labels=labels_order, output_dict=True)
    return (
        pd.DataFrame(cm, index=labels_order, columns=labels_order),
        pd.DataFrame(report).T,
        y_true,
        y_pred,
    )

# ========= è·ç¦»ç´¢å¼• & ç™¾åˆ†ä½å·¥å…· =========
@st.cache_resource
def build_distance_index(X_scaled: np.ndarray, cluster_labels: np.ndarray):
    labels = np.unique(cluster_labels)
    labels = labels[labels != -1]
    centers = {}
    dists_by_label = {}
    for lb in labels:
        pts = X_scaled[cluster_labels == lb]
        center = pts.mean(axis=0)
        centers[lb] = center
        d = euclidean_distances(pts, center.reshape(1, -1)).reshape(-1)
        dists_by_label[lb] = d
    global_dists = np.concatenate(list(dists_by_label.values())) if dists_by_label else np.array([])
    return centers, dists_by_label, global_dists

def percentile_rank(arr: np.ndarray, value: float) -> float:
    if arr.size == 0:
        return float("nan")
    return float((arr <= value).mean() * 100.0)

def size_band_text(ratio: float) -> str:
    if ratio >= 0.20:   # >=20%
        return "å¸¸è§"
    if ratio >= 0.05:   # 5%~20%
        return "ä¸å¸¸è§"
    return "å¾ˆå°‘è§"

def humanize_diffs(top_diffs):
    name_map = {
        "LOG_PRICE": "ä»·æ ¼ï¼ˆå¯¹æ•°ï¼‰", "PRICE": "ä»·æ ¼",
        "BEDROOM_BED_RATIO": "å§å®¤/åºŠä½æ¯”ä¾‹",
        "LISTING_DENSITY": "æ´»è·ƒåº¦ï¼ˆè¯„è®º/å¯è®¢å¤©æ•°ï¼‰",
        "LOG_HOST_LISTINGS_COUNT": "æˆ¿ä¸œä¸Šæ¶æ•°ï¼ˆå¯¹æ•°ï¼‰",
        "LOG_AVAILABILITY_365": "å¯è®¢å¤©æ•°ï¼ˆå¯¹æ•°ï¼‰",
        "LOG_REVIEWS_PER_MONTH": "æœˆå‡è¯„è®ºï¼ˆå¯¹æ•°ï¼‰",
    }
    friendly = []
    for r in top_diffs:
        z = r["z_diff"]
        if abs(z) >= 2.5:
            level = "æ˜æ˜¾"
        elif abs(z) >= 1.5:
            level = "æœ‰ç‚¹"
        else:
            level = "è½»å¾®"
        friendly.append({
            "feature": r["feature"],
            "name": name_map.get(r["feature"], r["feature"]),
            "direction": "åé«˜" if z > 0 else "åä½",
            "level": level,
            "abs_z": r["abs_z"]
        })
    return friendly

# ========= OpenAI Key & è°ƒç”¨ =========
def _get_api_key():
    key = None
    try:
        key = st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        pass
    if not key:
        import os
        key = os.getenv("OPENAI_API_KEY")
    return key

def call_llm_explainer(model: str, system_prompt: str, user_prompt: str):
    from openai import OpenAI
    client = OpenAI(api_key=_get_api_key())
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.2,
    )
    return resp.choices[0].message.content.strip()

# ========= äº²æ°‘å£å» Prompt =========
def build_prompts(city: str, decision: dict, top_diffs: list[dict], raw_input: dict | None = None):
    system_prompt = (
        "ä½ æ˜¯çŸ­ç§Ÿå¹³å°çš„ç”¨æˆ·æ²Ÿé€šåŠ©æ‰‹ã€‚è¯·ç”¨**å£è¯­åŒ–ã€æ˜“æ‡‚ã€å‹å¥½**çš„ä¸­æ–‡è§£é‡ŠåŸå› ï¼Œ"
        "é¿å…ä¸“ä¸šæœ¯è¯­ï¼ˆä¸è¦è¯´â€œz åˆ†æ•°ã€æ ‡å‡†å·®ã€é˜ˆå€¼ã€å‘é‡è·ç¦»â€ç­‰ï¼‰ã€‚"
        "è¾“å‡ºç»“æ„å›ºå®šï¼š\n"
        "ã€ä¸€å¥è¯ç»“è®ºã€‘ç”¨ 20 å­—ä»¥å†…è¯´æ˜å¤§æ„ï¼›\n"
        "ã€å“ªé‡Œä¸å¤ªå¯¹ã€‘åˆ— 3 ç‚¹ä»¥å†…ï¼Œæè¿°â€œæ¯”åŒç±»åé«˜/åä½â€ï¼Œç”¨'æ˜æ˜¾/æœ‰ç‚¹'ç­‰è¯ï¼›\n"
        "ã€æˆ‘è¯¥æ€ä¹ˆåšã€‘ç»™ 3~5 æ¡æ“ä½œå»ºè®®ï¼›\n"
        "ã€æ¸©é¦¨æç¤ºã€‘å¦‚æœ‰ä¸ç¡®å®šï¼Œæé†’å¯ä»¥äººå·¥å¤æ ¸ã€‚\n"
    )
    human = humanize_diffs(top_diffs)[:5]
    brief = {
        "city": city,
        "decision_type": decision.get("type"),
        "closest_cluster": decision.get("closest_cluster"),
        "distance_to_center": decision.get("distance_to_cluster_center"),
        "cluster_95pct_cutoff": decision.get("abnormal_cutoff"),
        "cluster_size_ratio": decision.get("cluster_size_ratio"),
        "human_diffs": [{"name": d["name"], "direction": d["direction"], "level": d["level"]} for d in human],
        "raw_input_preview": {k: raw_input[k] for k in ["PRICE","BEDROOMS","BEDS","ROOM_TYPE","PROPERTY_TYPE"]
                              if raw_input and (k in raw_input)}
    }
    user_prompt = (
        "è¯·ä¸¥æ ¼æŒ‰ä¸Šè¿°ç»“æ„è¾“å‡ºï¼Œä¸è¦æ³„éœ²å†…éƒ¨ç®—æ³•æˆ–é—¨æ§›åè¯ã€‚\n"
        f"å‚è€ƒæ‘˜è¦ï¼ˆJSONï¼‰ï¼š\n{json.dumps(brief, ensure_ascii=False, indent=2)}"
    )
    return system_prompt, user_prompt

# ============== UIï¼šå…¨å±€çŠ¶æ€ & åŸå¸‚é€‰æ‹© ==============
st.title("")

# ä¼šè¯çŠ¶æ€ï¼ˆé˜²æ­¢æŒ‰é’®é‡è·‘ä¸¢å¤±ç»“æœ & LLM ç¼“å­˜ï¼‰
for k, v in {"last_result": None, "last_user_input": None, "last_city": None, "llm_sig": None, "llm_text": None}.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ä¾§è¾¹æ 
st.sidebar.header("è®¾ç½®")
city_keys = list(CITY_OPTIONS.keys())
city_labels = [CITY_OPTIONS[c]["label"] for c in city_keys]
_city_idx = st.sidebar.selectbox("é€‰æ‹©åŸå¸‚ City", list(range(len(city_keys))),
                                 format_func=lambda i: city_labels[i], index=0, key="city_select")
CITY = city_keys[_city_idx]
st.sidebar.caption(f"å½“å‰åŸå¸‚ï¼š{CITY_OPTIONS[CITY]['label']}")

# åŠ è½½è¯¥åŸå¸‚å·¥ä»¶
try:
    scaler, top_features, X_scaled, cluster_labels = load_artifacts(CITY)
except RuntimeError as e:
    st.error(str(e))
    st.stop()

# Tabsï¼šå•æ¡é¢„æµ‹ / æ‰¹é‡è¯„ä¼°
tab_pred, tab_eval = st.tabs(["ğŸ” å•æ¡é¢„æµ‹ï¼ˆäº²æ°‘ç‰ˆï¼‰", "ğŸ“Š æ‰¹é‡è¯„ä¼°"])

# ------------------------- å•æ¡é¢„æµ‹ï¼ˆäº²æ°‘ç‰ˆï¼‰ -------------------------
with tab_pred:
    # è¾“å…¥å¡ç‰‡
    st.markdown('<div class="kcard glow">', unsafe_allow_html=True)
    st.markdown('<div class="section-title">è¾“å…¥ä¿¡æ¯</div>', unsafe_allow_html=True)

    with st.form(f"input_form_{CITY}", clear_on_submit=False):
        col1, col2 = st.columns(2)
        with col1:
            price = st.number_input("PRICE (USD)", min_value=0.0, value=120.0, step=1.0, key="inp_price")
            bedrooms = st.number_input("BEDROOMS", min_value=0.0, value=1.0, step=1.0, key="inp_bedrooms")
            beds = st.number_input("BEDS", min_value=0.0, value=1.0, step=1.0, key="inp_beds")
            reviews_per_month = st.number_input("REVIEWS_PER_MONTH", min_value=0.0, value=0.5, step=0.1, key="inp_rpm")
        with col2:
            availability_365 = st.number_input("AVAILABILITY_365", min_value=0.0, value=120.0, step=1.0, key="inp_avail")
            host_listings_count = st.number_input("HOST_LISTINGS_COUNT", min_value=0.0, value=1.0, step=1.0, key="inp_hlc")

        st.markdown('<div class="section-title" style="margin-top:4px;">ç±»åˆ«ç‰¹å¾</div>', unsafe_allow_html=True)
        room_type = st.text_input("ROOM_TYPEï¼ˆå¦‚ Entire home/aptï¼‰", value="Entire home/apt", key="inp_roomtype")
        property_type = st.text_input("PROPERTY_TYPEï¼ˆå¦‚ Apartmentï¼‰", value="Apartment", key="inp_proptype")

        default_rare = CITY_OPTIONS[CITY]["default_rare_threshold"]
        rare_threshold = st.slider("Rare é˜ˆå€¼ï¼ˆç°‡å æ¯”ï¼‰", 0.0, 0.2, float(default_rare), 0.01,
                                   help="å°äºè¯¥ç°‡å æ¯”å°†æ ‡è®°ä¸º rareï¼ˆè‹¥æœªè¶Šè¿‡å¼‚å¸¸è·ç¦»é˜ˆå€¼ï¼‰",
                                   key="inp_rare_thr")

        submitted = st.form_submit_button("ğŸš€ é¢„æµ‹", use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

    # æ–°æäº¤ï¼šè®¡ç®—å¹¶æŒä¹…åŒ–
    if submitted:
        user_input_raw = {
            "PRICE": price,
            "REVIEWS_PER_MONTH": reviews_per_month,
            "HOST_LISTINGS_COUNT": host_listings_count,
            "AVAILABILITY_365": availability_365,
            "BEDROOMS": bedrooms,
            "BEDS": beds,
            "ROOM_TYPE": room_type,
            "PROPERTY_TYPE": property_type,
            "CITY": CITY,
        }
        with st.spinner(f"({CITY}) æ¨ç†ä¸­â€¦"):
            result = classify_listing_from_raw_input(
                user_input_raw=user_input_raw,
                top_features=top_features,
                scaler=scaler,
                X_scaled=X_scaled,
                cluster_labels=cluster_labels,
                rare_threshold=rare_threshold
            )
        st.session_state["last_result"] = result
        st.session_state["last_user_input"] = user_input_raw
        st.session_state["last_city"] = CITY
        # æ–°é¢„æµ‹åæ¸…ç©ºä¸Šæ¬¡ LLM æ–‡æœ¬ï¼Œé¿å…é”™é…
        st.session_state["llm_sig"] = None
        st.session_state["llm_text"] = None

    # å±•ç¤ºï¼šä¼šè¯é‡Œæœ‰ç»“æœå°±æ¸²æŸ“
    has_cached = st.session_state["last_result"] is not None
    if submitted or has_cached:
        result = st.session_state["last_result"] if not submitted else result
        user_input_raw = st.session_state["last_user_input"] if not submitted else user_input_raw
        city_of_result = st.session_state.get("last_city", CITY)

        if city_of_result != CITY:
            st.info(f"å½“å‰åŸå¸‚åˆ‡æ¢ä¸º {CITY}ï¼Œä»¥ä¸‹ç»“æœæ¥è‡ª {city_of_result}ã€‚è¯·ç‚¹å‡»â€œğŸš€ é¢„æµ‹â€ä»¥æ›´æ–°ã€‚")

        # â€”â€” äº²æ°‘ç»“æœå¤´éƒ¨ï¼šçŠ¶æ€å¾½ç«  â€”â€”
        label = result.get("type", "unknown")
        badge_html = {
            "typical": '<span class="badge badge-green">âœ… çœ‹èµ·æ¥æŒºæ­£å¸¸çš„</span>',
            "rare": '<span class="badge badge-yellow">ğŸŸ¡ æœ‰ç‚¹å°‘è§ï¼ˆä¸ä¸€å®šæ˜¯é—®é¢˜ï¼‰</span>',
            "anomaly": '<span class="badge badge-red">ğŸ›‘ ä¸åŒç±»å·®è·è¾ƒå¤§ï¼Œå»ºè®®è‡ªæŸ¥</span>',
        }.get(label, '<span class="badge">â„¹ï¸ ç»“æœæœªçŸ¥</span>')

        st.markdown('<div class="kcard glow" style="margin-top:12px;">', unsafe_allow_html=True)
        st.markdown('<div class="section-title">ç»“æœ</div>', unsafe_allow_html=True)
        st.markdown(badge_html, unsafe_allow_html=True)

        # â€”â€” ä½ç½®æ„ŸçŸ¥ï¼ˆç™¾åˆ†ä½ï¼‰ & é£é™©å¸¦ â€”â€”
        centers, dists_by_label, global_dists = build_distance_index(X_scaled, cluster_labels)
        closest = result.get("closest_cluster")
        user_dist = result.get("distance_to_cluster_center", float("nan"))
        cutoff = result.get("abnormal_cutoff", float("nan"))
        cluster_ratio = result.get("cluster_size_ratio", float("nan"))

        p_in_cluster = percentile_rank(dists_by_label.get(closest, np.array([])), user_dist)
        p_global = percentile_rank(global_dists, user_dist)
        band = size_band_text(cluster_ratio if cluster_ratio == cluster_ratio else 0.0)

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**åŒç±»ä¸­çš„ä½ç½®**")
            try:
                import plotly.graph_objects as go
                fig1 = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=p_in_cluster,
                    title={"text": "åŒç°‡è·ç¦»ç™¾åˆ†ä½ï¼ˆ%ï¼‰"},
                    gauge={"axis":{"range":[0,100]}, "bar":{"thickness":0.25},
                           "steps":[
                               {"range":[0,80], "color":"#17351f"},
                               {"range":[80,95], "color":"#3c3310"},
                               {"range":[95,100], "color":"#3a1518"},
                           ]}
                ))
                st.plotly_chart(fig1, use_container_width=True)
            except Exception:
                st.progress(min(max(int(p_in_cluster),0),100))
                st.caption(f"{p_in_cluster:.1f}%")
            st.caption("æ•°å€¼è¶Šé«˜è¯´æ˜ä¸åŒç±»å·®å¼‚è¶Šå¤§ï¼›â‰¥95% é€šå¸¸è§†ä¸ºå¼‚å¸¸å€™é€‰ã€‚")

        with c2:
            st.markdown("**å…¨åŸä¸­çš„ä½ç½®**")
            try:
                import plotly.graph_objects as go
                fig2 = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=p_global,
                    title={"text": "å…¨å±€è·ç¦»ç™¾åˆ†ä½ï¼ˆ%ï¼‰"},
                    gauge={"axis":{"range":[0,100]}, "bar":{"thickness":0.25},
                           "steps":[
                               {"range":[0,80], "color":"#17351f"},
                               {"range":[80,95], "color":"#3c3310"},
                               {"range":[95,100], "color":"#3a1518"},
                           ]}
                ))
                st.plotly_chart(fig2, use_container_width=True)
            except Exception:
                st.progress(min(max(int(p_global),0),100))
                st.caption(f"{p_global:.1f}%")
            st.caption("ä¸å…¨åŸæ‰€æœ‰æˆ¿æºç›¸æ¯”çš„ç›¸å¯¹ä½ç½®ã€‚")

        st.markdown(f"**è¯¥ç±»å‹çš„å¸¸è§åº¦ï¼š** {band}ï¼ˆçº¦ {cluster_ratio:.1%} çš„æˆ¿æºå±äºè¿™ä¸€ç±»ï¼‰")

        # â€”â€” åŒç°‡è·ç¦»ç›´æ–¹å›¾ + ä½ çš„ä½ç½® & 95% é˜ˆå€¼ â€”â€”
        if closest in dists_by_label:
            try:
                import plotly.express as px
                df_hist = pd.DataFrame({"dist": dists_by_label[closest]})
                figh = px.histogram(df_hist, x="dist", nbins=30, title=f"ä¸ä½ æœ€åƒçš„ä¸€ç±»ï¼ˆç°‡ {closest}ï¼‰çš„è·ç¦»åˆ†å¸ƒ")
                figh.add_vline(x=user_dist, line_width=3, line_dash="dash", annotation_text="ä½ çš„ä½ç½®", annotation_position="top")
                figh.add_vline(x=cutoff, line_width=2, line_dash="dot", line_color="#ff9aa2", annotation_text="95% é˜ˆå€¼", annotation_position="top left")
                st.plotly_chart(figh, use_container_width=True)
            except Exception:
                st.write("ï¼ˆç›´æ–¹å›¾éœ€è¦ plotlyï¼Œå¯é€‰å®‰è£…ï¼špip install plotlyï¼‰")

            # âœ… è¿™é‡Œæ˜¯ä½ æçš„â€œè§£é‡Šè¿™å¼ å›¾â€çš„è¯´æ˜ï¼ˆæ”¾åœ¨å›¾ä¸‹æ–¹ï¼‰
            st.info(
                "è¿™å¼ å›¾å±•ç¤ºçš„æ˜¯ï¼šåœ¨â€œä¸ä½ æœ€åƒçš„ä¸€ç±»æˆ¿æºâ€é‡Œï¼Œå„ä¸ªæˆ¿æºåˆ°è¯¥ç±»ä¸­å¿ƒçš„è·ç¦»åˆ†å¸ƒã€‚"
                "é å·¦ä»£è¡¨æ›´æ¥è¿‘è¯¥ç±»çš„å…¸å‹æ ·å­ï¼Œè¶Šå¾€å³è¶Šåç¦»ã€‚è™šçº¿æ˜¯ä½ çš„ä½ç½®ï¼›"
                "ç²‰è‰²ç‚¹çº¿æ˜¯**95% é˜ˆå€¼**ï¼ˆè¶…è¿‡å®ƒé€šå¸¸è§†ä¸ºå¼‚å¸¸å€™é€‰ï¼‰ã€‚"
            )

        st.markdown('</div>', unsafe_allow_html=True)  # ç»“æŸç»“æœå¡ç‰‡

        # â€”â€” è‡ªåŠ¨ç”Ÿæˆ LLM å£è¯­åŒ–è§£é‡Šï¼ˆä»… rare/anomaly æ—¶ï¼‰ â€”â€”
        if label in {"rare", "anomaly"}:
            # è®¡ç®— top_diffsï¼ˆå¼‚å¸¸è´¡çŒ®åº¦ï¼‰ä½œä¸º LLM çš„ä¾æ®
            mask = (cluster_labels == closest)
            cluster_points = X_scaled[mask]

            df_tmp = pd.DataFrame([user_input_raw])
            df_tmp["LOG_PRICE"] = np.log1p(df_tmp["PRICE"])
            df_tmp["LOG_REVIEWS_PER_MONTH"] = np.log1p(df_tmp["REVIEWS_PER_MONTH"])
            df_tmp["LOG_HOST_LISTINGS_COUNT"] = np.log1p(df_tmp["HOST_LISTINGS_COUNT"])
            df_tmp["LOG_AVAILABILITY_365"] = np.log1p(df_tmp["AVAILABILITY_365"])
            df_tmp["LISTING_DENSITY"] = df_tmp["REVIEWS_PER_MONTH"] / (df_tmp["AVAILABILITY_365"] + 1)
            df_tmp["BEDROOM_BED_RATIO"] = df_tmp["BEDROOMS"] / (df_tmp["BEDS"] + 1)
            room_dum = pd.get_dummies(df_tmp.get("ROOM_TYPE", pd.Series(dtype=str)), prefix="ROOM_TYPE")
            prop_dum = pd.get_dummies(df_tmp.get("PROPERTY_TYPE", pd.Series(dtype=str)), prefix="PROPERTY_TYPE")
            df_tmp = pd.concat([df_tmp, room_dum, prop_dum], axis=1)
            for col in top_features:
                if col not in df_tmp.columns:
                    df_tmp[col] = 0
            X_user_now = df_tmp[top_features]
            X_user_scaled_now = scaler.transform(X_user_now)

            # top_diffs è®¡ç®—
            mu = cluster_points.mean(axis=0)
            sigma = cluster_points.std(axis=0, ddof=1) + 1e-8
            x = X_user_scaled_now.reshape(-1)
            z = (x - mu) / sigma
            order = np.argsort(-np.abs(z))[:8]
            top_diffs = []
            for idx in order:
                top_diffs.append({
                    "feature": top_features[idx],
                    "z_diff": float(z[idx]),
                    "abs_z": float(abs(z[idx])),
                    "center": float(mu[idx]),
                    "user": float(x[idx])
                })

            # ç”Ÿæˆ LLM ç­¾åï¼ˆé¿å…é‡å¤è¯·æ±‚ï¼‰
            sig_src = {
                "city": city_of_result,
                "label": label,
                "closest": int(closest) if closest is not None else -999,
                "user_dist": user_dist,
                "cutoff": cutoff,
                "input_hash": hashlib.md5(json.dumps(user_input_raw, sort_keys=True).encode()).hexdigest(),
            }
            sig = hashlib.md5(json.dumps(sig_src, sort_keys=True).encode()).hexdigest()

            st.markdown('<div class="kcard glow" style="margin-top:12px;">', unsafe_allow_html=True)
            st.markdown('<div class="section-title">ğŸ§  å£è¯­åŒ–è§£é‡Š & ä¸‹ä¸€æ­¥è¯¥æ€ä¹ˆåš</div>', unsafe_allow_html=True)

            api_key = _get_api_key()
            if not api_key:
                st.warning("ç¼ºå°‘ OPENAI_API_KEYï¼ˆç¯å¢ƒå˜é‡æˆ– st.secretsï¼‰ã€‚å› æ­¤æš‚ä¸ç”Ÿæˆ AI è§£é‡Šã€‚")
            else:
                # è‹¥ç­¾åå˜åŒ–æˆ–æ²¡æœ‰ç¼“å­˜ï¼Œå°±è°ƒç”¨ LLM
                if st.session_state["llm_sig"] != sig or not st.session_state["llm_text"]:
                    system_prompt, user_prompt = build_prompts(
                        city=city_of_result,
                        decision=result,
                        top_diffs=top_diffs,
                        raw_input=user_input_raw
                    )
                    with st.spinner("AI æ­£åœ¨ç”Ÿæˆå£è¯­åŒ–è§£é‡Šâ€¦"):
                        try:
                            text = call_llm_explainer("gpt-4o-mini", system_prompt, user_prompt)
                            st.session_state["llm_sig"] = sig
                            st.session_state["llm_text"] = text
                        except Exception as e:
                            st.session_state["llm_text"] = None
                            st.error(f"è°ƒç”¨ LLM å¤±è´¥ï¼š{e}")

                if st.session_state["llm_text"]:
                    st.chat_message("assistant").markdown(st.session_state["llm_text"])

            st.markdown('</div>', unsafe_allow_html=True)

        # å¯é€‰ï¼šæŠŠç™¾åˆ†ä½ç­‰å†™å› resultï¼Œä¾¿äºå¯¼å‡º/å¤ç”¨
        result["percentile_in_cluster"] = round(p_in_cluster, 2)
        result["percentile_global"] = round(p_global, 2)
        result["size_band"] = band
        st.session_state["last_result"] = result  # åˆ·æ–°ç¼“å­˜

# ------------------------- æ‰¹é‡è¯„ä¼° -------------------------
with tab_eval:
    st.markdown('<div class="kcard glow">', unsafe_allow_html=True)
    st.markdown('<div class="section-title">æ‰¹é‡è¯„ä¼°</div>', unsafe_allow_html=True)

    default_path = Path(__file__).parent / CITY / "full_test_listings.json"
    test_listings = None

    if default_path.exists():
        with open(default_path, "r") as f:
            test_listings = json.load(f)
        st.caption(f"å·²è‡ªåŠ¨åŠ è½½ï¼š{default_path.as_posix()}")
    else:
        up = st.file_uploader("ä¸Šä¼  full_test_listings.jsonï¼ˆlist[dict]ï¼Œæ¯æ¡åŒ…å« LABELï¼‰", type=["json"], key="eval_uploader")
        if up is not None:
            test_listings = json.load(up)

    if test_listings is not None:
        with st.spinner(f"({CITY}) è¯„ä¼°ä¸­â€¦"):
            cm_df, report_df, y_true, y_pred = evaluate_anomaly_detector(
                test_listings=test_listings,
                classify_func=classify_listing_from_raw_input,
                top_features=top_features,
                scaler=scaler,
                X_scaled=X_scaled,
                cluster_labels=cluster_labels
            )

        # æ··æ·†çŸ©é˜µï¼ˆæœ‰ plotly åˆ™çƒ­åŠ›å›¾ï¼Œæ²¡è£…åˆ™è¡¨æ ¼ï¼‰
        try:
            import plotly.express as px
            fig_cm = px.imshow(cm_df.values,
                               x=list(cm_df.columns), y=list(cm_df.index),
                               text_auto=True, aspect="auto", title="Confusion Matrix")
            st.plotly_chart(fig_cm, use_container_width=True)
        except Exception:
            st.write("### æ··æ·†çŸ©é˜µ")
            st.dataframe(cm_df, use_container_width=True)

        # åˆ†ç±»æŠ¥å‘Šï¼ˆAgGrid ä¼˜å…ˆï¼‰
        st.write("### åˆ†ç±»æŠ¥å‘Š")
        try:
            from st_aggrid import AgGrid, GridOptionsBuilder
            gob = GridOptionsBuilder.from_dataframe(report_df)
            gob.configure_default_column(resizable=True, sortable=True, filter=True)
            gob.configure_grid_options(domLayout='autoHeight')
            AgGrid(report_df, gridOptions=gob.build(), fit_columns_on_grid_load=True, theme="alpine")
        except Exception:
            st.dataframe(report_df, use_container_width=True)
    else:
        st.info(f"è¯·ä¸Šä¼ æˆ–æ”¾ç½® `{(Path(__file__).parent / CITY / 'full_test_listings.json').as_posix()}` åå†å¼€å§‹è¯„ä¼°ã€‚")

    st.markdown('</div>', unsafe_allow_html=True)

# ------------------------- é¡µè„š -------------------------
st.markdown('<div class="footer">Â© AirGuard â€” anomaly detection & insights</div>', unsafe_allow_html=True)
